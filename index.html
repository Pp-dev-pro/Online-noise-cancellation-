<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>RNNoise Web — Single-file Demo (Working Start/Stop)</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
<style>
  :root{
    --bg:#061017; --card:rgba(255,255,255,0.03); --muted:#9fb3c6; --accent:#4bd3ff;
  }
  html,body{height:100%; margin:0; font-family:Inter,system-ui,Roboto,Arial; background:
    radial-gradient(800px 400px at 10% 10%, rgba(75,211,255,0.02), transparent 10%),
    linear-gradient(180deg,#04101a 0%, #06131a 100%); color:#e8f6fb;}
  .wrap{max-width:1100px;margin:28px auto;padding:22px;}
  header{display:flex;gap:16px;align-items:center}
  h1{margin:0;font-size:1.4rem}
  p.lead{margin:0;color:var(--muted);font-size:0.95rem}

  .controls{display:flex;gap:10px;flex-wrap:wrap;margin-top:16px;align-items:center}
  .btn{background:linear-gradient(180deg,#0f2130,#071218);border:1px solid rgba(255,255,255,0.04);
    color:#dff7ff;padding:10px 14px;border-radius:10px;cursor:pointer;box-shadow:0 8px 24px rgba(0,0,0,0.6);}
  .btn.primary{background:linear-gradient(180deg,#06b6ff,#0284c7); color:#012; font-weight:700;}
  .btn.ghost{background:transparent;border:1px dashed rgba(255,255,255,0.03);color:var(--muted);}
  .btn:disabled{opacity:0.45;cursor:not-allowed}

  .card{background:var(--card);border-radius:12px;padding:14px;margin-top:14px;backdrop-filter: blur(8px) saturate(120%);
    border:1px solid rgba(255,255,255,0.03);box-shadow:0 10px 30px rgba(0,0,0,0.6);transition:transform .25s}
  .card:hover{transform:translateY(-6px)}

  .grid{display:grid;grid-template-columns:1fr 360px;gap:14px;margin-top:14px;}
  @media (max-width:880px){ .grid{grid-template-columns:1fr} }

  canvas{width:100%;height:160px;background:#000;border-radius:8px;display:block}
  .meta{color:var(--muted);font-size:0.9rem;margin-top:8px}
  label.small{font-size:0.9rem;color:var(--muted);display:flex;gap:8px;align-items:center}
  input[type=range]{accent-color:var(--accent)}
  footer{margin-top:18px;color:var(--muted);font-size:0.85rem}
  .status { font-weight:600; color:#bfefff; }
  .mute-warning { color:#ffb4b4; font-weight:600; margin-top:8px;}
  .controls .spacer {flex:1}
  .link{color:var(--accent); text-decoration:none;}
  .small { font-size:0.85rem; color:var(--muted); }
</style>
</head>
<body>
  <div class="wrap">
    <header>
      <div>
        <h1>RNNoise Web — Working Demo</h1>
        <p class="lead">Single-file HTML demo. RNNoise WASM loaded from jsDelivr. Start → allow mic → denoising runs. Use headphones.</p>
      </div>
      <div style="margin-left:auto;text-align:right">
        <div class="meta small">Frame size: <strong>480 samples</strong></div>
      </div>
    </header>

    <div class="controls">
      <button id="startBtn" class="btn primary">Start</button>
      <button id="stopBtn" class="btn" disabled>Stop</button>
      <button id="toggleBtn" class="btn ghost" disabled>Disable Denoise</button>

      <div class="spacer"></div>

      <label class="small">Gain <input id="gain" type="range" min="0" max="2" step="0.01" value="1"></label>
      <label class="small">Mix <input id="mix" type="range" min="0" max="1" step="0.01" value="0"></label>
    </div>

    <div class="grid">
      <div>
        <div class="card">
          <h3 style="margin:0 0 8px 0">Waveform (input)</h3>
          <canvas id="wave"></canvas>
          <div class="meta">status: <span id="status" class="status">idle</span></div>
        </div>

        <div class="card" style="margin-top:12px">
          <h3 style="margin:0 0 8px 0">Spectrum (input)</h3>
          <canvas id="spectrum"></canvas>
          <div class="meta" id="peaks">Detected peaks: —</div>
        </div>
      </div>

      <div>
        <div class="card">
          <h3 style="margin:0 0 8px 0">Info</h3>
          <div class="meta">WASM module: <span id="wasm">not loaded</span></div>
          <div class="meta">Denoiser: <span id="denstate">none</span></div>
          <div class="meta">Latency: <span id="lat">—</span></div>
        </div>

        <div class="card" style="margin-top:12px">
          <h3 style="margin:0 0 8px 0">Notes</h3>
          <div class="meta small">This single HTML imports the RNNoise WASM package from jsDelivr (@shiguredo/rnnoise-wasm). For best latency use AudioWorklet + sync WASM.</div>
        </div>
      </div>
    </div>

    <footer>Serve via HTTPS. If denoiser fails to load, the UI will still show waveform.</footer>
  </div>

<script type="module">
/*
 Single-file RNNoise demo.
 - Dynamically imports RNNoise WASM package from jsDelivr.
 - Uses circular buffer + processing loop to produce denoised frames.
 - Keeps a processed-output queue so ScriptProcessor can always fill output (fixes previous zero-output problem).
 - Start/Stop fully clean up nodes and free RNNoise state.
*/

/* CDN path for @shiguredo/rnnoise-wasm (jsDelivr). If this breaks later, update version on this URL. */
const RNNOISE_MODULE = 'https://cdn.jsdelivr.net/npm/@shiguredo/rnnoise-wasm@2025.1.5/dist/index.js';

const FRAME_SIZE = 480;           // RNNoise frame size
const QUEUE_MAX_FRAMES = 64;     // processed frames queue capacity

// UI elements
const startBtn = document.getElementById('startBtn');
const stopBtn  = document.getElementById('stopBtn');
const toggleBtn= document.getElementById('toggleBtn');
const gainEl   = document.getElementById('gain');
const mixEl    = document.getElementById('mix');
const statusEl = document.getElementById('status');
const wasmEl   = document.getElementById('wasm');
const denstateEl = document.getElementById('denstate');
const latEl = document.getElementById('lat');
const peaksEl = document.getElementById('peaks');

const waveCanvas = document.getElementById('wave');
const specCanvas = document.getElementById('spectrum');
const wctx = waveCanvas.getContext('2d');
const sctx = specCanvas.getContext('2d');

let audioCtx = null, micStream = null, srcNode = null;
let scriptNode = null, gainNode = null, analyser = null, freqAnalyser = null;

let rn = null, denoiser = null, denoiseEnabled = true;

// circular input buffer (Float32), pointers
let circBuf = null, circWrite = 0, circLen = 0, circCap = 0;

// processed frames queue (Array of Float32Array), read/write pointers
let processedQueue = [], processedRead = 0;

// small helper: resize canvases for DPR
function resizeCanvas(c){
  const rect = c.getBoundingClientRect();
  const dpr = window.devicePixelRatio || 1;
  c.width = Math.round(rect.width * dpr);
  c.height= Math.round(rect.height * dpr);
  return {w:c.width,h:c.height,dpr};
}

// draw visualizers
function draw(){
  requestAnimationFrame(draw);
  if(!analyser) return;

  // waveform
  const buf = new Uint8Array(analyser.fftSize);
  analyser.getByteTimeDomainData(buf);
  const {w:ww,h:wh} = resizeCanvas(waveCanvas);
  wctx.fillStyle = '#000'; wctx.fillRect(0,0,ww,wh);
  wctx.lineWidth = 2 * (window.devicePixelRatio||1);
  wctx.strokeStyle = '#4ee7c6'; wctx.beginPath();
  for(let i=0;i<buf.length;i++){
    const x = (i / buf.length) * ww;
    const y = (buf[i]/255) * wh;
    if(i===0) wctx.moveTo(x,y); else wctx.lineTo(x,y);
  }
  wctx.stroke();

  // spectrum
  const fbuf = new Uint8Array(freqAnalyser.frequencyBinCount);
  freqAnalyser.getByteFrequencyData(fbuf);
  const {w:fw,h:fh} = resizeCanvas(specCanvas);
  sctx.fillStyle = '#000'; sctx.fillRect(0,0,fw,fh);
  const barW = fw / fbuf.length;
  // show top peaks
  const peaks = [];
  for(let i=0;i<fbuf.length;i++){
    if(fbuf[i] > 220) peaks.push(i);
  }
  peaksEl.textContent = peaks.length ? peaks.slice(0,6).map(i => Math.round((i * (audioCtx.sampleRate || 48000)) / (fbuf.length*2)) + 'Hz').join(', ') : '—';
  for(let i=0;i<fbuf.length;i++){
    const v = fbuf[i] / 255;
    sctx.fillStyle = `hsl(${Math.round((i/fbuf.length)*280)},80%,60%)`;
    sctx.fillRect(i*barW, fh - v*fh, barW*0.9, v*fh);
  }
}

// load RNNoise module from CDN (dynamic ESM import)
async function loadRnnoise(){
  if(rn) return rn;
  try{
    const mod = await import(RNNOISE_MODULE);
    // package exports Rnnoise in different shapes; check
    const Rnnoise = mod?.Rnnoise ?? mod?.default?.Rnnoise ?? mod?.default;
    if(!Rnnoise) throw new Error('RNNoise export not found in module');
    const api = await Rnnoise.load(); // loads WASM and returns API object
    rn = api;
    wasmEl.textContent = 'loaded';
    return rn;
  }catch(e){
    console.error('Failed to load RNNoise WASM:', e);
    wasmEl.textContent = 'load failed';
    throw e;
  }
}

// start audio pipeline
async function start(){
  if(audioCtx) return;
  statusEl.textContent = 'starting';
  try{
    micStream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount:1, echoCancellation:false, noiseSuppression:false, autoGainControl:false } });
  }catch(e){
    statusEl.textContent = 'mic denied';
    console.error(e); return;
  }

  audioCtx = new (window.AudioContext || window.webkitAudioContext)({ latencyHint: 'interactive' });
  srcNode = audioCtx.createMediaStreamSource(micStream);

  // analysers for visuals
  analyser = audioCtx.createAnalyser(); analyser.fftSize = 2048;
  freqAnalyser = audioCtx.createAnalyser(); freqAnalyser.fftSize = 4096;
  srcNode.connect(analyser);
  srcNode.connect(freqAnalyser);

  // circular buffer to hold incoming float samples; capacity = FRAME_SIZE * 16
  circCap = FRAME_SIZE * 16;
  circBuf = new Float32Array(circCap);
  circWrite = 0; circLen = 0;

  // processed queue reset
  processedQueue = []; processedRead = 0;

  // create script processor (small buffer for lower latency)
  const bufferSize = 128; // keep small but compatible
  scriptNode = audioCtx.createScriptProcessor(bufferSize, 1, 1);

  // ensure rnnoise loaded and create denoiser
  try{
    await loadRnnoise();
    if(rn && !denoiser){
      denoiser = rn.createDenoiseState();
      denstateEl.textContent = 'created';
      toggleBtn.disabled = false;
      denoiseEnabled = true;
      toggleBtn.textContent = 'Disable Denoise';
    }
  }catch(e){
    // allow running without denoiser (visuals)
    console.warn('Continuing without RNNoise denoiser');
  }

  // gain node and connect chain: src -> scriptNode -> gain -> dest
  gainNode = audioCtx.createGain(); gainNode.gain.value = parseFloat(gainEl.value);
  srcNode.connect(scriptNode);
  scriptNode.connect(gainNode);
  gainNode.connect(audioCtx.destination);

  // audio processing: write incoming input to circular buffer, process frames as they become available,
  // enqueue processed frames into processedQueue. ScriptProcessor's onaudioprocess will also output processed frames when available.
  scriptNode.onaudioprocess = function(evt){
    const input = evt.inputBuffer.getChannelData(0);
    const output = evt.outputBuffer.getChannelData(0);

    // write into circular buffer
    for(let i=0;i<input.length;i++){
      circBuf[circWrite] = input[i];
      circWrite = (circWrite + 1) % circCap;
      if(circLen < circCap) circLen++; else { /*overflow, advance read*/ }
    }

    // If we have enough samples to form a FRAME_SIZE, process as many frames as possible (but limit to queue capacity)
    while(denoiseEnabled && denoiser && circLen >= FRAME_SIZE && processedQueue.length < QUEUE_MAX_FRAMES){
      const frame = new Float32Array(FRAME_SIZE);
      // copy FRAME_SIZE starting from (circWrite - circLen) position (i.e. oldest data). Compute read index:
      // We'll maintain a read pointer implicitly: compute readPos = (circWrite - circLen + circCap) % circCap
      let readPos = (circWrite - circLen + circCap) % circCap;
      for(let k=0;k<FRAME_SIZE;k++){
        frame[k] = circBuf[(readPos + k) % circCap];
      }
      // call rnnoise (mutates frame)
      try{
        denoiser.processFrame(frame);
      }catch(e){
        console.warn('rnnoise processFrame error', e);
      }
      // advance the circular buffer's consumed samples
      circLen -= FRAME_SIZE;
      // enqueue processed frame
      processedQueue.push(frame);
      // keep processedQueue bounded
      if(processedQueue.length > QUEUE_MAX_FRAMES) processedQueue.shift();
    }

    // Fill output from processedQueue if available (copy from head frame)
    let outIdx = 0;
    while(outIdx < output.length){
      if(processedQueue.length > 0){
        const head = processedQueue[0];
        if(!head._pos) head._pos = 0;
        // copy as many samples as possible from head into output
        while(outIdx < output.length && head._pos < head.length){
          const processedSample = head[head._pos++];
          // apply gain and mix: mix slider blends processed with silence (we could keep raw passthrough but to avoid echo/feedback, we keep processed only)
          const mix = parseFloat(mixEl.value);
          const processedWithGain = processedSample * parseFloat(gainEl.value);
          // if mix>0 we would need original input samples — for safety and to avoid feedback we use processed only and allow user to lower mix to 0
          output[outIdx++] = processedWithGain * (1 - mix) + 0 * mix;
        }
        // if head consumed completely, shift it out
        if(head._pos >= head.length) processedQueue.shift();
      } else {
        // no processed data ready — output silence to avoid feedback
        output[outIdx++] = 0;
      }
    }
  };

  // UI updates
  startBtn.disabled = true; stopBtn.disabled = false;
  statusEl.textContent = 'running';
  latEl.textContent = ((audioCtx.baseLatency || 0) * 1000).toFixed(1) + ' ms';
  draw();
}

// stop and cleanup
function stop(){
  // disconnect nodes and stop mic tracks
  try{ if(srcNode) srcNode.disconnect(); }catch(e){}
  try{ if(scriptNode) scriptNode.disconnect(); scriptNode.onaudioprocess = null; }catch(e){}
  try{ if(gainNode) gainNode.disconnect(); }catch(e){}
  try{ if(micStream) micStream.getTracks().forEach(t=>t.stop()); }catch(e){}
  // destroy denoiser state if created
  try{ if(denoiser){ denoiser.destroy(); denoiser = null; denstateEl.textContent = 'destroyed'; } }catch(e){ console.warn(e); }
  // close audio context
  try{ if(audioCtx) audioCtx.close(); }catch(e){}
  // reset variables
  audioCtx = null; micStream = null; srcNode = null; scriptNode = null; gainNode = null; analyser = null; freqAnalyser = null;
  circBuf = null; circCap = 0; circLen = 0; circWrite = 0;
  processedQueue = []; processedRead = 0;
  startBtn.disabled = false; stopBtn.disabled = true; toggleBtn.disabled = true;
  statusEl.textContent = 'stopped';
  latEl.textContent = '—';
}

// toggle denoise on/off
function toggleDenoise(){
  denoiseEnabled = !denoiseEnabled;
  toggleBtn.textContent = denoiseEnabled ? 'Disable Denoise' : 'Enable Denoise';
  statusEl.textContent = denoiseEnabled ? 'denoising' : 'passthrough';
}

startBtn.addEventListener('click', async ()=>{
  try{
    await start();
    toggleBtn.disabled = false;
    toggleBtn.textContent = denoiseEnabled ? 'Disable Denoise' : 'Enable Denoise';
  }catch(e){
    console.error('Start failed', e);
    statusEl.textContent = 'start failed';
    startBtn.disabled = false;
  }
});
stopBtn.addEventListener('click', stop);
toggleBtn.addEventListener('click', toggleDenoise);

// gain and mix control
gainEl.addEventListener('input', ()=>{ if(gainNode) gainNode.gain.value = parseFloat(gainEl.value); });
mixEl.addEventListener('input', ()=>{/*mix used in processing*/});

// initial resize
function initialResize(){ resizeCanvas(waveCanvas); resizeCanvas(specCanvas); }
window.addEventListener('resize', initialResize);
initialResize();

</script>
</body>
</html>
