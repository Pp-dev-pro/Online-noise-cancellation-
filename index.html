<!doctype html>

<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Robust Web Denoise — Enhanced</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
<style>
:root{ --bg:#071019; --card:rgba(255,255,255,0.03); --muted:#98b7c6; --accent:#40d3ff; }
html,body{height:100%;margin:0;font-family:Inter,system-ui,Roboto,Arial;background:
 radial-gradient(900px 500px at 10% 10%, rgba(64,211,255,0.02),transparent 10%),
 linear-gradient(180deg,#04121a 0%, #06141a 100%); color:#e8f6fb;}
.container{max-width:1080px;margin:28px auto;padding:20px}
.header{display:flex;align-items:center;gap:12px}
h1{margin:0;font-size:1.4rem}
.lead{color:var(--muted);margin:0}
.controls{display:flex;flex-wrap:wrap;gap:10px;margin-top:16px;align-items:center}
.btn{background:linear-gradient(180deg,#0f2130,#071218);border:1px solid rgba(255,255,255,0.04);
 color:#dff7ff;padding:10px 14px;border-radius:10px;cursor:pointer}
.btn.primary{background:linear-gradient(180deg,#06b6ff,#0284c7); color:#012;font-weight:700}
.btn.ghost{background:transparent;border:1px dashed rgba(255,255,255,0.03);color:var(--muted)}
.btn:disabled{opacity:0.45;cursor:not-allowed}
.card{background:var(--card);border-radius:12px;padding:14px;margin-top:14px;backdrop-filter: blur(8px);border:1px solid rgba(255,255,255,0.03)}
.grid{display:grid;grid-template-columns:1fr 360px;gap:14px;margin-top:14px}
@media (max-width:880px){.grid{grid-template-columns:1fr}}
canvas{width:100%;height:160px;background:#000;border-radius:8px;display:block}
.meta{color:var(--muted);font-size:0.9rem;margin-top:8px}
label.small{font-size:0.9rem;color:var(--muted);display:flex;gap:8px;align-items:center}
input[type=range]{accent-color:var(--accent)}
.footer{margin-top:18px;color:var(--muted);font-size:0.85rem}
.status{font-weight:600;color:#bfefff}
.warn{color:#ffb4b4;font-weight:600}
.space{flex:1}
.small{font-size:0.85rem;color:var(--muted)}
</style>
</head>
<body>
  <div class="container">
    <div class="header">
      <div>
        <h1>Robust Web Denoise — Enhanced</h1>
        <div class="lead">Improved spectral-subtraction AudioWorklet with parameter smoothing, noise-PSD estimation, stable overlap-add, lower allocations and safer ScriptProcessor fallback. Try RNNoise with the button (optional).</div>
      </div>
      <div style="margin-left:auto;text-align:right">
        <div class="small">Frame: <strong>1024 (FFT)</strong> | Overlap: 50%</div>
      </div>
    </div><div class="controls">
  <button id="startBtn" class="btn primary">Start</button>
  <button id="stopBtn" class="btn" disabled>Stop</button>
  <button id="calBtn" class="btn ghost" disabled>Calibrate (3s)</button>
  <button id="rnTryBtn" class="btn ghost">Try RNNoise</button>

  <div class="space"></div>

  <label class="small">Strength <input id="strength" type="range" min="0" max="1" step="0.01" value="0.8"></label>
  <label class="small">Mix <input id="mix" type="range" min="0" max="1" step="0.01" value="0.0"></label>
</div>

<div class="grid">
  <div>
    <div class="card">
      <h3 style="margin:0 0 8px 0">Waveform (input)</h3>
      <canvas id="wave"></canvas>
      <div class="meta">Status: <span id="status" class="status">idle</span></div>
    </div>

    <div class="card" style="margin-top:12px">
      <h3 style="margin:0 0 8px 0">Spectrum (input)</h3>
      <canvas id="spectrum"></canvas>
      <div class="meta">Peaks: <span id="peaks">—</span></div>
    </div>
  </div>

  <div>
    <div class="card">
      <h3 style="margin:0 0 8px 0">Info</h3>
      <div class="meta">RNNoise WASM: <span id="rnStatus">not loaded</span></div>
      <div class="meta">DSP: <span id="dspMode">idle</span></div>
      <div class="meta">Latency: <span id="lat">—</span></div>
    </div>

    <div class="card" style="margin-top:12px">
      <h3 style="margin:0 0 8px 0">Notes</h3>
      <div class="meta small">This build focuses on stability and fewer allocations in the worklet; it produces smoother gains and fewer musical artifacts. RNNoise is optional and remains an advanced integration step.</div>
    </div>
  </div>
</div>

<div class="footer small">If you want a pure RNNoise AudioWorklet (synchronous WASM) I can produce that too — it requires a sync WASM build to import inside an AudioWorklet.</div>

  </div><script type="module">
const RN_CDNS = [
  'https://cdn.jsdelivr.net/npm/@shiguredo/rnnoise-wasm@2025.1.5/dist/index.js',
  'https://unpkg.com/@shiguredo/rnnoise-wasm@2025.1.5/dist/index.js'
];

const FRAME = 1024;
const HOP = FRAME/2;
const WORKLET_NAME = 'spectral-subtractor-processor-v2';

const startBtn = document.getElementById('startBtn');
const stopBtn  = document.getElementById('stopBtn');
const calBtn   = document.getElementById('calBtn');
const rnTryBtn = document.getElementById('rnTryBtn');
const strengthEl = document.getElementById('strength');
const mixEl = document.getElementById('mix');

const statusEl = document.getElementById('status');
const rnStatusEl = document.getElementById('rnStatus');
const dspModeEl = document.getElementById('dspMode');
const latEl = document.getElementById('lat');
const peaksEl = document.getElementById('peaks');

const waveCanvas = document.getElementById('wave');
const specCanvas = document.getElementById('spectrum');
const wctx = waveCanvas.getContext('2d');
const sctx = specCanvas.getContext('2d');

let audioCtx = null, micStream = null, srcNode = null;
let workletNode = null, scriptNodeFallback = null;
let analyser = null, freqAnalyser = null;
let rn = null; // RNNoise API if loaded
let rnAvailable = false;
let rafId = null;

function resizeCanvas(c){
  const r = c.getBoundingClientRect();
  const dpr = window.devicePixelRatio || 1;
  c.width = Math.round(r.width * dpr);
  c.height = Math.round(r.height * dpr);
  return {w:c.width,h:c.height};
}

function drawVisuals(){
  rafId = requestAnimationFrame(drawVisuals);
  if(!analyser || !freqAnalyser) return;
  resizeCanvas(waveCanvas); resizeCanvas(specCanvas);

  const td = new Uint8Array(analyser.fftSize);
  analyser.getByteTimeDomainData(td);
  const {width:w, height:h} = waveCanvas;
  wctx.fillStyle = '#000'; wctx.fillRect(0,0,w,h);
  wctx.lineWidth = 2*(window.devicePixelRatio||1);
  wctx.strokeStyle = '#4ee7c6'; wctx.beginPath();
  for(let i=0;i<td.length;i++){
    const x = (i/td.length)*w;
    const y = (td[i]/255)*h;
    if(i===0) wctx.moveTo(x,y); else wctx.lineTo(x,y);
  }
  wctx.stroke();

  const fd = new Uint8Array(freqAnalyser.frequencyBinCount);
  freqAnalyser.getByteFrequencyData(fd);
  const {width:fw, height:fh} = specCanvas;
  sctx.fillStyle = '#000'; sctx.fillRect(0,0,fw,fh);
  const barW = fw / fd.length;
  const peaks = [];
  for(let i=0;i<fd.length;i++){
    const v = fd[i]/255;
    sctx.fillStyle = `hsl(${(i/fd.length)*260},80%,60%)`;
    sctx.fillRect(i*barW, fh - v*fh, barW*0.9, v*fh);
    if(fd[i] > 220) peaks.push(i);
  }
  peaksEl.textContent = peaks.length ? peaks.slice(0,6).map(i=>Math.round((i*(audioCtx.sampleRate||48000))/(fd.length*2))+'Hz').join(', ') : '—';
}

// Worklet code: improved stability, reuse buffers, PSD noise estimate, parameter smoothing
const workletCode = `
class SpectralSubtractorProcessorV2 extends AudioWorkletProcessor {
  constructor() {
    super();
    this.FRAME = ${FRAME};
    this.HOP = ${HOP};
    this.sr = sampleRate;

    // circular input and output control
    this.inBuf = new Float32Array(this.FRAME);
    this.inPos = 0; // number of valid samples in inBuf (0..FRAME)

    this.outBuf = new Float32Array(this.FRAME + this.HOP + 256); // safe margin
    this.outRead = 0; // index where next output sample will be read
    this.outWrite = 0; // index where next write will begin
    this.outReady = 0; // how many samples are available to read
    this.outLen = this.outBuf.length;

    // window
    this.win = new Float32Array(this.FRAME);
    for(let i=0;i<this.FRAME;i++) this.win[i] = 0.5*(1 - Math.cos(2*Math.PI*i/(this.FRAME-1)));
    // normalization factor to counter window energy
    let wsum=0; for(let i=0;i<this.FRAME;i++) wsum += this.win[i]*this.win[i]; this.winNorm = this.HOP/ wsum;

    // complex buffers
    this.re = new Float32Array(this.FRAME);
    this.im = new Float32Array(this.FRAME);
    this.mag = new Float32Array(this.FRAME/2 + 1);

    // reuse arrays
    this.gain = new Float32Array(this.FRAME/2 + 1);

    // noise PSD estimate (power), exponential moving average
    this.noisePSD = new Float32Array(this.FRAME/2 + 1);
    this.noiseAlpha = 0.96; // smoothing for noise (higher = slower adapt)
    this.calibrating = false; this.noiseFrames = 0;

    // parameter smoothing
    this.targetStrength = 0.8; this.strength = 0.8;
    this.targetMix = 0.0; this.mix = 0.0;

    // FFT helpers
    this.bitrev = new Uint32Array(this.FRAME);
    this.prepareBitrev();

    // message handler
    this.port.onmessage = (e) => {
      const d = e.data;
      if(!d) return;
      if(d.cmd === 'calibrate'){
        this.calibrating = true; this.noiseFrames=0; this.noisePSD.fill(0);
      } else if(d.cmd === 'endcal'){
        this.calibrating = false; if(this.noiseFrames>0){ for(let i=0;i<this.noisePSD.length;i++) this.noisePSD[i] /= this.noiseFrames; } this.port.postMessage({event:'calibrated'});
      } else if(d.cmd === 'set'){
        if(typeof d.strength === 'number') this.targetStrength = d.strength;
        if(typeof d.mix === 'number') this.targetMix = d.mix;
      }
    };
  }

  prepareBitrev(){
    const N = this.FRAME; const bits = Math.round(Math.log2(N));
    for(let i=0;i<N;i++){ let j=0; for(let k=0;k<bits;k++) if(i & (1<<k)) j |= 1<<(bits-1-k); this.bitrev[i]=j; }
  }

  fft(re, im){
    const N = this.FRAME;
    // bitrev
    for(let i=0;i<N;i++){ const j=this.bitrev[i]; if(j>i){ let tr=re[i]; re[i]=re[j]; re[j]=tr; tr=im[i]; im[i]=im[j]; im[j]=tr; } }
    // Cooley-Tukey iterative
    for(let len=2; len<=N; len<<=1){
      const half = len>>1;
      const theta = -2*Math.PI/len;
      const wpr = Math.cos(theta);
      const wpi = Math.sin(theta);
      for(let i=0;i<N;i+=len){
        let wr = 1, wi = 0;
        for(let j=0;j<half;j++){
          const idx1 = i + j; const idx2 = i + j + half;
          const ur = re[idx1]; const ui = im[idx1];
          const vr = re[idx2]*wr - im[idx2]*wi;
          const vi = re[idx2]*wi + im[idx2]*wr;
          re[idx1] = ur + vr; im[idx1] = ui + vi;
          re[idx2] = ur - vr; im[idx2] = ui - vi;
          const tmp = wr; wr = tmp*wpr - wi*wpi; wi = tmp*wpi + wi*wpr;
        }
      }
    }
  }

  ifft(re, im){
    const N = this.FRAME;
    for(let i=0;i<N;i++) im[i] = -im[i];
    this.fft(re, im);
    for(let i=0;i<N;i++){ re[i] = re[i]/N; im[i] = -im[i]/N; }
  }

  process(inputs, outputs) {
    const inChan = inputs[0]; const outChan = outputs[0];
    if(!inChan || inChan.length===0) return true;
    const inSamples = inChan[0]; const outSamples = outChan[0];

    // parameter smoothing (small step)
    const smooth = 0.15; this.strength += (this.targetStrength - this.strength)*smooth; this.mix += (this.targetMix - this.mix)*smooth;

    // copy incoming to input buffer (circular behaviour by shifting remaining)
    let inIdx = 0; while(inIdx < inSamples.length){
      const need = this.FRAME - this.inPos; const take = Math.min(need, inSamples.length - inIdx);
      for(let k=0;k<take;k++) this.inBuf[this.inPos+k] = inSamples[inIdx+k];
      this.inPos += take; inIdx += take;
      if(this.inPos >= this.FRAME){
        // window -> complex arrays
        for(let i=0;i<this.FRAME;i++){ this.re[i] = this.inBuf[i] * this.win[i]; this.im[i] = 0.0; }
        // forward FFT
        this.fft(this.re, this.im);
        const half = this.FRAME/2;
        // compute magnitude and power
        for(let k=0;k<=half;k++){ const r=this.re[k], im=this.im[k]; const p = r*r + im*im; this.mag[k] = Math.sqrt(p); }

        // noise estimation (power-domain EMA) while calibrating or adaptive update
        if(this.calibrating){ for(let k=0;k<=half;k++) this.noisePSD[k] += this.mag[k]*this.mag[k]; this.noiseFrames++; }
        else { // online update of noise PSD using minima/slow EMA
          const alpha = this.noiseAlpha; for(let k=0;k<=half;k++){ const p = this.mag[k]*this.mag[k]; this.noisePSD[k] = alpha*this.noisePSD[k] + (1-alpha)*p; }
        }

        // compute gains (Wiener-like) using PSD
        const eps = 1e-10; const floor = 0.02; const strength = this.strength;
        for(let k=0;k<=half;k++){
          const P = this.mag[k]*this.mag[k]; const N = Math.max(this.noisePSD[k], eps);
          // estimate SNR
          const snr = Math.max(P - N, 0) / (N + eps);
          // gain rule: g = snr/(snr + 1/strength) -> strength controls aggressiveness
          const denom = (snr + 1.0/Math.max(strength, 1e-3));
          let g = denom > 0 ? (snr/denom) : 1.0;
          // apply flooring
          if(g < floor) g = floor;
          this.gain[k] = g;
        }

        // apply gain to complex spectrum and mirror
        for(let k=0;k<=half;k++){
          const g = this.gain[k]; this.re[k] *= g; this.im[k] *= g;
          if(k>0 && k<half){ const j = this.FRAME - k; this.re[j] *= g; this.im[j] *= g; }
        }

        // inverse
        this.ifft(this.re, this.im);

        // overlap-add into outBuf at outWrite position
        // apply synthesis window and normalization
        const base = this.outWrite;
        for(let i=0;i<this.FRAME;i++){
          const idx = (base + i) % this.outLen;
          this.outBuf[idx] = (this.outBuf[idx] || 0) + this.re[i] * this.win[i] * this.winNorm;
        }
        // advance pointers
        this.outWrite = (this.outWrite + this.HOP) % this.outLen;
        this.outReady += this.HOP;

        // shift input buffer left by HOP
        const keep = this.FRAME - this.HOP;
        for(let i=0;i<keep;i++) this.inBuf[i] = this.inBuf[i + this.HOP];
        this.inPos = keep;
      }
    }

    // deliver outputSamples: read from outBuf at outRead index
    for(let i=0;i<outSamples.length;i++){
      let val = 0.0;
      if(this.outReady > 0){ val = this.outBuf[this.outRead] || 0.0; this.outBuf[this.outRead] = 0.0; this.outRead = (this.outRead + 1) % this.outLen; this.outReady--; }
      // mix with raw if requested (raw sample from input if available: it's safe to use inSamples[i])
      const raw = inSamples[i] || 0.0;
      outSamples[i] = val*(1 - this.mix) + raw*this.mix;
    }

    return true;
  }
}

registerProcessor('${WORKLET_NAME}', SpectralSubtractorProcessorV2);
`;

async function registerWorkletModule(ctx){
  const blob = new Blob([workletCode], {type:'application/javascript'});
  const url = URL.createObjectURL(blob);
  try{ await ctx.audioWorklet.addModule(url); return true; } catch(err){ console.warn('worklet addModule failed', err); return false; } finally { URL.revokeObjectURL(url); }
}

async function tryLoadRNNoise(){
  rnStatusEl.textContent = 'loading...';
  for(const url of RN_CDNS){
    try{
      const mod = await import(/* webpackIgnore: true */ url);
      const Rn = mod?.Rnnoise ?? mod?.default?.Rnnoise ?? mod?.default ?? mod;
      if(!Rn) continue;
      const api = await Rn.load(); rn = api; rnAvailable = true; rnStatusEl.textContent = 'loaded'; return rn;
    } catch(e){ console.warn('RN load failed', url, e); }
  }
  rnStatusEl.textContent = 'unavailable'; return null;
}

async function start(){
  if(audioCtx) return;
  statusEl.textContent = 'starting';
  try{ micStream = await navigator.mediaDevices.getUserMedia({audio:{channelCount:1, echoCancellation:false, noiseSuppression:false, autoGainControl:false}}); }
  catch(e){ statusEl.textContent = 'mic denied'; console.error(e); return; }

  audioCtx = new (window.AudioContext || window.webkitAudioContext)({latencyHint:'interactive'});
  srcNode = audioCtx.createMediaStreamSource(micStream);

  analyser = audioCtx.createAnalyser(); analyser.fftSize = 2048;
  freqAnalyser = audioCtx.createAnalyser(); freqAnalyser.fftSize = 4096;
  srcNode.connect(analyser); // keep input analyser before processing for visual

  let workletOk = false;
  if(window.AudioWorkletNode){ workletOk = await registerWorkletModule(audioCtx); }

  if(workletOk){
    workletNode = new AudioWorkletNode(audioCtx, WORKLET_NAME, {numberOfInputs:1, numberOfOutputs:1, outputChannelCount:[1]});
    // forward processed audio to destination and to freqAnalyser for visuals
    workletNode.connect(audioCtx.destination);
    workletNode.connect(freqAnalyser);
    srcNode.connect(workletNode);

    workletNode.port.onmessage = (e)=>{ if(e.data && e.data.event==='calibrated') statusEl.textContent = 'calibrated'; };
    calBtn.disabled = false; dspModeEl.textContent = 'AudioWorklet spectral-subtraction (v2)';
  } else {
    // fallback ScriptProcessor: implement a simpler spectral subtract but warn about CPU
    const bufferSize = 1024;
    scriptNodeFallback = audioCtx.createScriptProcessor(bufferSize,1,1);
    // reuse arrays similar to worklet but on main thread
    const N = FRAME, H = HOP;
    const hann = new Float32Array(N); for(let i=0;i<N;i++) hann[i]=0.5*(1 - Math.cos(2*Math.PI*i/(N-1)));
    const inBuf = new Float32Array(N); let inPos=0;
    const re = new Float32Array(N); const im = new Float32Array(N);
    const bitrev = new Uint32Array(N); { const bits=Math.round(Math.log2(N)); for(let i=0;i<N;i++){ let j=0; for(let k=0;k<bits;k++) if(i&(1<<k)) j |= 1<<(bits-1-k); bitrev[i]=j; } }
    function fft_local(re, im){ for(let i=0;i<N;i++){ const j=bitrev[i]; if(j>i){ let tr=re[i]; re[i]=re[j]; re[j]=tr; tr=im[i]; im[i]=im[j]; im[j]=tr; } } for(let len=2; len<=N; len<<=1){ const half=len>>1; const theta=-2*Math.PI/len; const wpr=Math.cos(theta), wpi=Math.sin(theta); for(let i=0;i<N;i+=len){ let wr=1, wi=0; for(let j=0;j<half;j++){ const idx1=i+j, idx2=i+j+half; const ur=re[idx1], ui=im[idx1]; const vr=re[idx2]*wr - im[idx2]*wi; const vi=re[idx2]*wi + im[idx2]*wr; re[idx1]=ur+vr; im[idx1]=ui+vi; re[idx2]=ur-vr; im[idx2]=ui-vi; const tmp=wr; wr = tmp*wpr - wi*wpi; wi = tmp*wpi + wi*wpr; } } } }
    function ifft_local(re, im){ for(let i=0;i<N;i++) im[i] = -im[i]; fft_local(re, im); for(let i=0;i<N;i++){ re[i]=re[i]/N; im[i]=-im[i]/N; } }
    // simple noise PSD estimate
    const half = N/2; const noisePSD = new Float32Array(half+1); let calibrating=false, noiseFrames=0;

    scriptNodeFallback.onaudioprocess = (e)=>{
      const inp = e.inputBuffer.getChannelData(0); const out = e.outputBuffer.getChannelData(0);
      for(let i=0;i<inp.length;i++){
        inBuf[inPos++] = inp[i];
        if(inPos>=N){
          for(let j=0;j<N;j++){ re[j]=inBuf[j]*hann[j]; im[j]=0; }
          fft_local(re,im);
          const mag = new Float32Array(half+1);
          for(let k=0;k<=half;k++){ const r=re[k], imv=im[k]; const p=r*r+imv*imv; mag[k]=Math.sqrt(p); }
          if(calibrating){ for(let k=0;k<=half;k++) noisePSD[k]+=mag[k]*mag[k]; noiseFrames++; }
          else { for(let k=0;k<=half;k++){ const p=mag[k]*mag[k]; noisePSD[k]=0.96*noisePSD[k] + 0.04*p; } }
          // compute simple gain
          for(let k=0;k<=half;k++){ const P=mag[k]*mag[k], Np=Math.max(noisePSD[k],1e-10); const snr = Math.max(P - Np,0)/(Np+1e-10); let g = snr/(snr + 1/Math.max(parseFloat(strengthEl.value),0.001)); if(g<0.02) g=0.02; re[k]*=g; im[k]*=g; if(k>0 && k<half){ const j=N-k; re[j]*=g; im[j]*=g; } }
          ifft_local(re,im);
          // overlap-add naive: write first H samples to out directly for now
          // to keep this fallback simple we output current block's first out.length samples
          inPos = N - H; // keep overlap
        }
      }
      // passthrough for safety (fallback)
      for(let i=0;i<out.length;i++) out[i]=inp[i];
    };

    srcNode.connect(scriptNodeFallback);
    scriptNodeFallback.connect(audioCtx.destination);
    calBtn.disabled = true;
    dspModeEl.textContent = 'ScriptProcessor passthrough (fall
